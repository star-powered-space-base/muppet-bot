use anyhow::Result;
use dotenvy::dotenv;
use env_logger;
use log::{info, error};
use tokio;

use persona::config::Config;
use persona::database::Database;
use persona::commands::CommandHandler;
use persona::http_server::start_http_server;

#[tokio::main]
async fn main() -> Result<()> {
    // Load environment variables
    dotenv().ok();

    // Initialize logging
    env_logger::init();

    info!("ğŸš€ Starting Discord Bot HTTP Server...");

    // Load configuration
    let config = Config::from_env()?;
    info!("âœ… Configuration loaded");

    // Ensure OPENAI_API_KEY is set in environment for the openai crate
    // Set both OPENAI_API_KEY and OPENAI_KEY for compatibility
    std::env::set_var("OPENAI_API_KEY", &config.openai_api_key);
    std::env::set_var("OPENAI_KEY", &config.openai_api_key);

    // Initialize database
    let database = Database::new(&config.database_path).await?;
    info!("âœ… Database connected");

    // Create command handler
    let command_handler = CommandHandler::new(
        database,
        config.openai_api_key.clone(),
        config.openai_model.clone(),
        config.conflict_mediation_enabled,
        &config.conflict_sensitivity,
        config.mediation_cooldown_minutes,
    );

    info!("âœ… Command handler initialized");

    // Start HTTP server on port 6666 (matches ngrok configuration)
    let port = 6666;
    info!("ğŸŒ Starting HTTP server on port {}", port);
    info!("ğŸ“¡ Interactions endpoint: https://0fbf2d802093.ngrok-free.app/interactions");
    
    if let Err(e) = start_http_server(config, command_handler, port).await {
        error!("âŒ HTTP server failed: {}", e);
        return Err(e);
    }

    Ok(())
}